{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data for MNIST\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "train_kwargs = {\"batch_size\": 64}\n",
    "test_kwargs = {\"batch_size\":1000}\n",
    "dataset1 = datasets.MNIST(\"../data\", train=True, download=True, transform=transform)\n",
    "dataset2 = datasets.MNIST(\"../data\", train=False, transform=transform)\n",
    "\n",
    "# We split the training pool into training and holdback for later sampling\n",
    "train_size = int(0.5 * len(dataset1))\n",
    "sample_from_size = len(dataset1) - train_size\n",
    "train_dataset, sample_from_dataset = torch.utils.data.random_split(dataset1, [train_size, sample_from_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, **train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our CNN to train on MNIST\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "def attach_forward_hook(model, array):\n",
    "    return model.register_forward_hook(\n",
    "        lambda model, input, output: array.append(output.data.detach().tolist())\n",
    "    )\n",
    "\n",
    "def infer(model, device, data_loader, resource_uris, label_classes, inference_classes):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target, resource_uri in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # why are we calculating loss here?\n",
    "            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            for resource_uri, label_class, inference_class in zip(resource_uri, target.data.detach().tolist(), pred.data.detach().flatten().tolist()):\n",
    "                resource_uris.append(resource_uri)\n",
    "                label_classes.append(label_class)\n",
    "                inference_classes.append(inference_class)\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss, correct, len(data_loader.dataset), 100.0 * correct / len(data_loader.dataset)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# We modify the MNIST dataset to expose some information about the source data\n",
    "# to allow us to uniquely identify an input in a way that we can recover it later\n",
    "class CustomDataset(datasets.MNIST):\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super().__getitem__(index)\n",
    "        resource_uri = f\"{'train' if self.train else 't10k'}-images-idx3-ubyte-{index}\"\n",
    "        return img, target, resource_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/30000 (0%)]\tLoss: 2.298323\n",
      "Train Epoch: 1 [640/30000 (2%)]\tLoss: 1.234064\n",
      "Train Epoch: 1 [1280/30000 (4%)]\tLoss: 0.720270\n",
      "Train Epoch: 1 [1920/30000 (6%)]\tLoss: 0.650934\n",
      "Train Epoch: 1 [2560/30000 (9%)]\tLoss: 0.529386\n",
      "Train Epoch: 1 [3200/30000 (11%)]\tLoss: 0.430856\n",
      "Train Epoch: 1 [3840/30000 (13%)]\tLoss: 0.261618\n",
      "Train Epoch: 1 [4480/30000 (15%)]\tLoss: 0.260083\n",
      "Train Epoch: 1 [5120/30000 (17%)]\tLoss: 0.213215\n",
      "Train Epoch: 1 [5760/30000 (19%)]\tLoss: 0.336469\n",
      "Train Epoch: 1 [6400/30000 (21%)]\tLoss: 0.263782\n",
      "Train Epoch: 1 [7040/30000 (23%)]\tLoss: 0.169521\n",
      "Train Epoch: 1 [7680/30000 (26%)]\tLoss: 0.185041\n",
      "Train Epoch: 1 [8320/30000 (28%)]\tLoss: 0.303260\n",
      "Train Epoch: 1 [8960/30000 (30%)]\tLoss: 0.574012\n",
      "Train Epoch: 1 [9600/30000 (32%)]\tLoss: 0.316354\n",
      "Train Epoch: 1 [10240/30000 (34%)]\tLoss: 0.125933\n",
      "Train Epoch: 1 [10880/30000 (36%)]\tLoss: 0.129972\n",
      "Train Epoch: 1 [11520/30000 (38%)]\tLoss: 0.083715\n",
      "Train Epoch: 1 [12160/30000 (41%)]\tLoss: 0.128034\n",
      "Train Epoch: 1 [12800/30000 (43%)]\tLoss: 0.132013\n",
      "Train Epoch: 1 [13440/30000 (45%)]\tLoss: 0.264951\n",
      "Train Epoch: 1 [14080/30000 (47%)]\tLoss: 0.125834\n",
      "Train Epoch: 1 [14720/30000 (49%)]\tLoss: 0.095360\n",
      "Train Epoch: 1 [15360/30000 (51%)]\tLoss: 0.175320\n",
      "Train Epoch: 1 [16000/30000 (53%)]\tLoss: 0.123401\n",
      "Train Epoch: 1 [16640/30000 (55%)]\tLoss: 0.086039\n",
      "Train Epoch: 1 [17280/30000 (58%)]\tLoss: 0.060460\n",
      "Train Epoch: 1 [17920/30000 (60%)]\tLoss: 0.470791\n",
      "Train Epoch: 1 [18560/30000 (62%)]\tLoss: 0.130438\n",
      "Train Epoch: 1 [19200/30000 (64%)]\tLoss: 0.286218\n",
      "Train Epoch: 1 [19840/30000 (66%)]\tLoss: 0.081297\n",
      "Train Epoch: 1 [20480/30000 (68%)]\tLoss: 0.101749\n",
      "Train Epoch: 1 [21120/30000 (70%)]\tLoss: 0.295679\n",
      "Train Epoch: 1 [21760/30000 (72%)]\tLoss: 0.110490\n",
      "Train Epoch: 1 [22400/30000 (75%)]\tLoss: 0.052510\n",
      "Train Epoch: 1 [23040/30000 (77%)]\tLoss: 0.130971\n",
      "Train Epoch: 1 [23680/30000 (79%)]\tLoss: 0.159707\n",
      "Train Epoch: 1 [24320/30000 (81%)]\tLoss: 0.089676\n",
      "Train Epoch: 1 [24960/30000 (83%)]\tLoss: 0.090303\n",
      "Train Epoch: 1 [25600/30000 (85%)]\tLoss: 0.034359\n",
      "Train Epoch: 1 [26240/30000 (87%)]\tLoss: 0.054563\n",
      "Train Epoch: 1 [26880/30000 (90%)]\tLoss: 0.068245\n",
      "Train Epoch: 1 [27520/30000 (92%)]\tLoss: 0.087814\n",
      "Train Epoch: 1 [28160/30000 (94%)]\tLoss: 0.158724\n",
      "Train Epoch: 1 [28800/30000 (96%)]\tLoss: 0.089732\n",
      "Train Epoch: 1 [29440/30000 (98%)]\tLoss: 0.197294\n",
      "\n",
      "Test set: Average loss: 0.0626, Accuracy: 9798/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/30000 (0%)]\tLoss: 0.130472\n",
      "Train Epoch: 2 [640/30000 (2%)]\tLoss: 0.028175\n",
      "Train Epoch: 2 [1280/30000 (4%)]\tLoss: 0.108785\n",
      "Train Epoch: 2 [1920/30000 (6%)]\tLoss: 0.200989\n",
      "Train Epoch: 2 [2560/30000 (9%)]\tLoss: 0.057609\n",
      "Train Epoch: 2 [3200/30000 (11%)]\tLoss: 0.073301\n",
      "Train Epoch: 2 [3840/30000 (13%)]\tLoss: 0.048917\n",
      "Train Epoch: 2 [4480/30000 (15%)]\tLoss: 0.124547\n",
      "Train Epoch: 2 [5120/30000 (17%)]\tLoss: 0.145805\n",
      "Train Epoch: 2 [5760/30000 (19%)]\tLoss: 0.212090\n",
      "Train Epoch: 2 [6400/30000 (21%)]\tLoss: 0.071320\n",
      "Train Epoch: 2 [7040/30000 (23%)]\tLoss: 0.031735\n",
      "Train Epoch: 2 [7680/30000 (26%)]\tLoss: 0.114660\n",
      "Train Epoch: 2 [8320/30000 (28%)]\tLoss: 0.033043\n",
      "Train Epoch: 2 [8960/30000 (30%)]\tLoss: 0.179898\n",
      "Train Epoch: 2 [9600/30000 (32%)]\tLoss: 0.196236\n",
      "Train Epoch: 2 [10240/30000 (34%)]\tLoss: 0.235045\n",
      "Train Epoch: 2 [10880/30000 (36%)]\tLoss: 0.049428\n",
      "Train Epoch: 2 [11520/30000 (38%)]\tLoss: 0.064991\n",
      "Train Epoch: 2 [12160/30000 (41%)]\tLoss: 0.019329\n",
      "Train Epoch: 2 [12800/30000 (43%)]\tLoss: 0.270344\n",
      "Train Epoch: 2 [13440/30000 (45%)]\tLoss: 0.090885\n",
      "Train Epoch: 2 [14080/30000 (47%)]\tLoss: 0.019145\n",
      "Train Epoch: 2 [14720/30000 (49%)]\tLoss: 0.060656\n",
      "Train Epoch: 2 [15360/30000 (51%)]\tLoss: 0.112234\n",
      "Train Epoch: 2 [16000/30000 (53%)]\tLoss: 0.024524\n",
      "Train Epoch: 2 [16640/30000 (55%)]\tLoss: 0.096903\n",
      "Train Epoch: 2 [17280/30000 (58%)]\tLoss: 0.034939\n",
      "Train Epoch: 2 [17920/30000 (60%)]\tLoss: 0.217272\n",
      "Train Epoch: 2 [18560/30000 (62%)]\tLoss: 0.074437\n",
      "Train Epoch: 2 [19200/30000 (64%)]\tLoss: 0.150028\n",
      "Train Epoch: 2 [19840/30000 (66%)]\tLoss: 0.053757\n",
      "Train Epoch: 2 [20480/30000 (68%)]\tLoss: 0.037997\n",
      "Train Epoch: 2 [21120/30000 (70%)]\tLoss: 0.159710\n",
      "Train Epoch: 2 [21760/30000 (72%)]\tLoss: 0.133203\n",
      "Train Epoch: 2 [22400/30000 (75%)]\tLoss: 0.039728\n",
      "Train Epoch: 2 [23040/30000 (77%)]\tLoss: 0.088573\n",
      "Train Epoch: 2 [23680/30000 (79%)]\tLoss: 0.026165\n",
      "Train Epoch: 2 [24320/30000 (81%)]\tLoss: 0.053174\n",
      "Train Epoch: 2 [24960/30000 (83%)]\tLoss: 0.101041\n",
      "Train Epoch: 2 [25600/30000 (85%)]\tLoss: 0.006769\n",
      "Train Epoch: 2 [26240/30000 (87%)]\tLoss: 0.007986\n",
      "Train Epoch: 2 [26880/30000 (90%)]\tLoss: 0.005515\n",
      "Train Epoch: 2 [27520/30000 (92%)]\tLoss: 0.117516\n",
      "Train Epoch: 2 [28160/30000 (94%)]\tLoss: 0.205610\n",
      "Train Epoch: 2 [28800/30000 (96%)]\tLoss: 0.054695\n",
      "Train Epoch: 2 [29440/30000 (98%)]\tLoss: 0.006199\n",
      "\n",
      "Test set: Average loss: 0.0466, Accuracy: 9851/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/30000 (0%)]\tLoss: 0.194348\n",
      "Train Epoch: 3 [640/30000 (2%)]\tLoss: 0.057114\n",
      "Train Epoch: 3 [1280/30000 (4%)]\tLoss: 0.026916\n",
      "Train Epoch: 3 [1920/30000 (6%)]\tLoss: 0.152834\n",
      "Train Epoch: 3 [2560/30000 (9%)]\tLoss: 0.009484\n",
      "Train Epoch: 3 [3200/30000 (11%)]\tLoss: 0.055494\n",
      "Train Epoch: 3 [3840/30000 (13%)]\tLoss: 0.044585\n",
      "Train Epoch: 3 [4480/30000 (15%)]\tLoss: 0.077360\n",
      "Train Epoch: 3 [5120/30000 (17%)]\tLoss: 0.090784\n",
      "Train Epoch: 3 [5760/30000 (19%)]\tLoss: 0.221811\n",
      "Train Epoch: 3 [6400/30000 (21%)]\tLoss: 0.040810\n",
      "Train Epoch: 3 [7040/30000 (23%)]\tLoss: 0.021267\n",
      "Train Epoch: 3 [7680/30000 (26%)]\tLoss: 0.027824\n",
      "Train Epoch: 3 [8320/30000 (28%)]\tLoss: 0.112127\n",
      "Train Epoch: 3 [8960/30000 (30%)]\tLoss: 0.159476\n",
      "Train Epoch: 3 [9600/30000 (32%)]\tLoss: 0.088154\n",
      "Train Epoch: 3 [10240/30000 (34%)]\tLoss: 0.054015\n",
      "Train Epoch: 3 [10880/30000 (36%)]\tLoss: 0.011359\n",
      "Train Epoch: 3 [11520/30000 (38%)]\tLoss: 0.019472\n",
      "Train Epoch: 3 [12160/30000 (41%)]\tLoss: 0.064503\n",
      "Train Epoch: 3 [12800/30000 (43%)]\tLoss: 0.244964\n",
      "Train Epoch: 3 [13440/30000 (45%)]\tLoss: 0.017504\n",
      "Train Epoch: 3 [14080/30000 (47%)]\tLoss: 0.017513\n",
      "Train Epoch: 3 [14720/30000 (49%)]\tLoss: 0.027174\n",
      "Train Epoch: 3 [15360/30000 (51%)]\tLoss: 0.086335\n",
      "Train Epoch: 3 [16000/30000 (53%)]\tLoss: 0.015804\n",
      "Train Epoch: 3 [16640/30000 (55%)]\tLoss: 0.051124\n",
      "Train Epoch: 3 [17280/30000 (58%)]\tLoss: 0.011943\n",
      "Train Epoch: 3 [17920/30000 (60%)]\tLoss: 0.275467\n",
      "Train Epoch: 3 [18560/30000 (62%)]\tLoss: 0.008253\n",
      "Train Epoch: 3 [19200/30000 (64%)]\tLoss: 0.135067\n",
      "Train Epoch: 3 [19840/30000 (66%)]\tLoss: 0.023651\n",
      "Train Epoch: 3 [20480/30000 (68%)]\tLoss: 0.017857\n",
      "Train Epoch: 3 [21120/30000 (70%)]\tLoss: 0.268560\n",
      "Train Epoch: 3 [21760/30000 (72%)]\tLoss: 0.107455\n",
      "Train Epoch: 3 [22400/30000 (75%)]\tLoss: 0.077357\n",
      "Train Epoch: 3 [23040/30000 (77%)]\tLoss: 0.112879\n",
      "Train Epoch: 3 [23680/30000 (79%)]\tLoss: 0.026267\n",
      "Train Epoch: 3 [24320/30000 (81%)]\tLoss: 0.009243\n",
      "Train Epoch: 3 [24960/30000 (83%)]\tLoss: 0.067099\n",
      "Train Epoch: 3 [25600/30000 (85%)]\tLoss: 0.025782\n",
      "Train Epoch: 3 [26240/30000 (87%)]\tLoss: 0.023816\n",
      "Train Epoch: 3 [26880/30000 (90%)]\tLoss: 0.003859\n",
      "Train Epoch: 3 [27520/30000 (92%)]\tLoss: 0.026710\n",
      "Train Epoch: 3 [28160/30000 (94%)]\tLoss: 0.018068\n",
      "Train Epoch: 3 [28800/30000 (96%)]\tLoss: 0.046657\n",
      "Train Epoch: 3 [29440/30000 (98%)]\tLoss: 0.045869\n",
      "\n",
      "Test set: Average loss: 0.0420, Accuracy: 9857/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/30000 (0%)]\tLoss: 0.149166\n",
      "Train Epoch: 4 [640/30000 (2%)]\tLoss: 0.049534\n",
      "Train Epoch: 4 [1280/30000 (4%)]\tLoss: 0.094536\n",
      "Train Epoch: 4 [1920/30000 (6%)]\tLoss: 0.155071\n",
      "Train Epoch: 4 [2560/30000 (9%)]\tLoss: 0.007777\n",
      "Train Epoch: 4 [3200/30000 (11%)]\tLoss: 0.051385\n",
      "Train Epoch: 4 [3840/30000 (13%)]\tLoss: 0.013292\n",
      "Train Epoch: 4 [4480/30000 (15%)]\tLoss: 0.170484\n",
      "Train Epoch: 4 [5120/30000 (17%)]\tLoss: 0.029523\n",
      "Train Epoch: 4 [5760/30000 (19%)]\tLoss: 0.153816\n",
      "Train Epoch: 4 [6400/30000 (21%)]\tLoss: 0.070677\n",
      "Train Epoch: 4 [7040/30000 (23%)]\tLoss: 0.015438\n",
      "Train Epoch: 4 [7680/30000 (26%)]\tLoss: 0.021132\n",
      "Train Epoch: 4 [8320/30000 (28%)]\tLoss: 0.016865\n",
      "Train Epoch: 4 [8960/30000 (30%)]\tLoss: 0.056352\n",
      "Train Epoch: 4 [9600/30000 (32%)]\tLoss: 0.109348\n",
      "Train Epoch: 4 [10240/30000 (34%)]\tLoss: 0.024150\n",
      "Train Epoch: 4 [10880/30000 (36%)]\tLoss: 0.005078\n",
      "Train Epoch: 4 [11520/30000 (38%)]\tLoss: 0.033749\n",
      "Train Epoch: 4 [12160/30000 (41%)]\tLoss: 0.026857\n",
      "Train Epoch: 4 [12800/30000 (43%)]\tLoss: 0.196201\n",
      "Train Epoch: 4 [13440/30000 (45%)]\tLoss: 0.041042\n",
      "Train Epoch: 4 [14080/30000 (47%)]\tLoss: 0.016862\n",
      "Train Epoch: 4 [14720/30000 (49%)]\tLoss: 0.028884\n",
      "Train Epoch: 4 [15360/30000 (51%)]\tLoss: 0.095331\n",
      "Train Epoch: 4 [16000/30000 (53%)]\tLoss: 0.051385\n",
      "Train Epoch: 4 [16640/30000 (55%)]\tLoss: 0.031775\n",
      "Train Epoch: 4 [17280/30000 (58%)]\tLoss: 0.003707\n",
      "Train Epoch: 4 [17920/30000 (60%)]\tLoss: 0.225228\n",
      "Train Epoch: 4 [18560/30000 (62%)]\tLoss: 0.007498\n",
      "Train Epoch: 4 [19200/30000 (64%)]\tLoss: 0.101019\n",
      "Train Epoch: 4 [19840/30000 (66%)]\tLoss: 0.017585\n",
      "Train Epoch: 4 [20480/30000 (68%)]\tLoss: 0.040928\n",
      "Train Epoch: 4 [21120/30000 (70%)]\tLoss: 0.024103\n",
      "Train Epoch: 4 [21760/30000 (72%)]\tLoss: 0.045200\n",
      "Train Epoch: 4 [22400/30000 (75%)]\tLoss: 0.014863\n",
      "Train Epoch: 4 [23040/30000 (77%)]\tLoss: 0.017499\n",
      "Train Epoch: 4 [23680/30000 (79%)]\tLoss: 0.011124\n",
      "Train Epoch: 4 [24320/30000 (81%)]\tLoss: 0.005656\n",
      "Train Epoch: 4 [24960/30000 (83%)]\tLoss: 0.045239\n",
      "Train Epoch: 4 [25600/30000 (85%)]\tLoss: 0.010266\n",
      "Train Epoch: 4 [26240/30000 (87%)]\tLoss: 0.005622\n",
      "Train Epoch: 4 [26880/30000 (90%)]\tLoss: 0.009692\n",
      "Train Epoch: 4 [27520/30000 (92%)]\tLoss: 0.029203\n",
      "Train Epoch: 4 [28160/30000 (94%)]\tLoss: 0.081889\n",
      "Train Epoch: 4 [28800/30000 (96%)]\tLoss: 0.026255\n",
      "Train Epoch: 4 [29440/30000 (98%)]\tLoss: 0.067458\n",
      "\n",
      "Test set: Average loss: 0.0387, Accuracy: 9874/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/30000 (0%)]\tLoss: 0.136928\n",
      "Train Epoch: 5 [640/30000 (2%)]\tLoss: 0.011820\n",
      "Train Epoch: 5 [1280/30000 (4%)]\tLoss: 0.021706\n",
      "Train Epoch: 5 [1920/30000 (6%)]\tLoss: 0.118827\n",
      "Train Epoch: 5 [2560/30000 (9%)]\tLoss: 0.055044\n",
      "Train Epoch: 5 [3200/30000 (11%)]\tLoss: 0.027003\n",
      "Train Epoch: 5 [3840/30000 (13%)]\tLoss: 0.004497\n",
      "Train Epoch: 5 [4480/30000 (15%)]\tLoss: 0.054288\n",
      "Train Epoch: 5 [5120/30000 (17%)]\tLoss: 0.011422\n",
      "Train Epoch: 5 [5760/30000 (19%)]\tLoss: 0.132768\n",
      "Train Epoch: 5 [6400/30000 (21%)]\tLoss: 0.016470\n",
      "Train Epoch: 5 [7040/30000 (23%)]\tLoss: 0.014864\n",
      "Train Epoch: 5 [7680/30000 (26%)]\tLoss: 0.051037\n",
      "Train Epoch: 5 [8320/30000 (28%)]\tLoss: 0.015959\n",
      "Train Epoch: 5 [8960/30000 (30%)]\tLoss: 0.077778\n",
      "Train Epoch: 5 [9600/30000 (32%)]\tLoss: 0.038299\n",
      "Train Epoch: 5 [10240/30000 (34%)]\tLoss: 0.027578\n",
      "Train Epoch: 5 [10880/30000 (36%)]\tLoss: 0.022504\n",
      "Train Epoch: 5 [11520/30000 (38%)]\tLoss: 0.049739\n",
      "Train Epoch: 5 [12160/30000 (41%)]\tLoss: 0.002592\n",
      "Train Epoch: 5 [12800/30000 (43%)]\tLoss: 0.125849\n",
      "Train Epoch: 5 [13440/30000 (45%)]\tLoss: 0.064967\n",
      "Train Epoch: 5 [14080/30000 (47%)]\tLoss: 0.009678\n",
      "Train Epoch: 5 [14720/30000 (49%)]\tLoss: 0.019725\n",
      "Train Epoch: 5 [15360/30000 (51%)]\tLoss: 0.011408\n",
      "Train Epoch: 5 [16000/30000 (53%)]\tLoss: 0.011918\n",
      "Train Epoch: 5 [16640/30000 (55%)]\tLoss: 0.010446\n",
      "Train Epoch: 5 [17280/30000 (58%)]\tLoss: 0.015019\n",
      "Train Epoch: 5 [17920/30000 (60%)]\tLoss: 0.322338\n",
      "Train Epoch: 5 [18560/30000 (62%)]\tLoss: 0.006964\n",
      "Train Epoch: 5 [19200/30000 (64%)]\tLoss: 0.104283\n",
      "Train Epoch: 5 [19840/30000 (66%)]\tLoss: 0.017230\n",
      "Train Epoch: 5 [20480/30000 (68%)]\tLoss: 0.055164\n",
      "Train Epoch: 5 [21120/30000 (70%)]\tLoss: 0.038541\n",
      "Train Epoch: 5 [21760/30000 (72%)]\tLoss: 0.012397\n",
      "Train Epoch: 5 [22400/30000 (75%)]\tLoss: 0.113896\n",
      "Train Epoch: 5 [23040/30000 (77%)]\tLoss: 0.027267\n",
      "Train Epoch: 5 [23680/30000 (79%)]\tLoss: 0.029263\n",
      "Train Epoch: 5 [24320/30000 (81%)]\tLoss: 0.012461\n",
      "Train Epoch: 5 [24960/30000 (83%)]\tLoss: 0.014530\n",
      "Train Epoch: 5 [25600/30000 (85%)]\tLoss: 0.008759\n",
      "Train Epoch: 5 [26240/30000 (87%)]\tLoss: 0.003273\n",
      "Train Epoch: 5 [26880/30000 (90%)]\tLoss: 0.002648\n",
      "Train Epoch: 5 [27520/30000 (92%)]\tLoss: 0.026919\n",
      "Train Epoch: 5 [28160/30000 (94%)]\tLoss: 0.071575\n",
      "Train Epoch: 5 [28800/30000 (96%)]\tLoss: 0.030208\n",
      "Train Epoch: 5 [29440/30000 (98%)]\tLoss: 0.020641\n",
      "\n",
      "Test set: Average loss: 0.0407, Accuracy: 9873/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and test our model\n",
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10== 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Determine Loss on the test set\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"mnist_cnn.pt\"))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.0145, Accuracy: 29863/30000 (100%)\n",
      "\n",
      "\n",
      "Average loss: 0.0489, Accuracy: 29598/30000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Inference on all data and generate embeddings\n",
    "inference_kwargs = {\"batch_size\": 1000}\n",
    "\n",
    "train_embeddings = []\n",
    "train_resource_uris = []\n",
    "train_label_classes = []\n",
    "train_inference_classes = []\n",
    "\n",
    "sample_from_embeddings = []\n",
    "sample_from_resource_uris = []\n",
    "sample_from_label_classes = []\n",
    "sample_from_inference_classes = []\n",
    "\n",
    "train_mnist_data = CustomDataset(\"../data\", train=True, transform=transform, download=True)\n",
    "train_dataset, sample_from_dataset = torch.utils.data.random_split(train_mnist_data, [train_size, sample_from_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# from train\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset, **inference_kwargs)\n",
    "hook = attach_forward_hook(model.fc2, train_embeddings)\n",
    "infer(model, device, data_loader, train_resource_uris, train_label_classes, train_inference_classes)\n",
    "hook.remove()\n",
    "\n",
    "# from sample_from\n",
    "data_loader = torch.utils.data.DataLoader(sample_from_dataset, **inference_kwargs)\n",
    "attach_forward_hook(model.fc2, sample_from_embeddings)\n",
    "infer(model, device, data_loader, sample_from_resource_uris, sample_from_label_classes, sample_from_inference_classes)\n",
    "\n",
    "# remove one dimension from embeddings\n",
    "train_embeddings = [item for sublist in train_embeddings for item in sublist]\n",
    "sample_from_embeddings = [item for sublist in sample_from_embeddings for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n",
      "60000\n",
      "time to fetch 60000 embeddings:  0.2901458740234375\n",
      "time to fetch 30000 embeddings:  0.09539914131164551\n",
      "time to fetch 30000 embeddings:  0.09370589256286621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeff/.pyenv/versions/3.9.2/lib/python3.9/site-packages/hdbscan/prediction.py:382: UserWarning: Clusterer does not have any defined clusters, new data will be automatically predicted as noise.\n",
      "  warn('Clusterer does not have any defined clusters, new data'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into Chroma\n",
    "api = chroma.get_api()\n",
    "api.reset()\n",
    "api.set_model_space(\"mnist\")\n",
    "\n",
    "api.add(\n",
    "    embedding= train_embeddings,\n",
    "    input_uri= train_resource_uris,\n",
    "    dataset= \"train\",\n",
    "    inference_class= train_inference_classes,\n",
    "    label_class= train_label_classes,\n",
    "    model_space= \"mnist\"\n",
    ")\n",
    "api.add(\n",
    "    embedding= sample_from_embeddings,\n",
    "    input_uri= sample_from_resource_uris,\n",
    "    dataset= \"test\",\n",
    "    inference_class= sample_from_inference_classes,\n",
    "    label_class= sample_from_label_classes,\n",
    "    model_space= \"mnist\"\n",
    ")\n",
    "\n",
    "print(api.count(model_space=\"mnist\"))\n",
    "api.process(training_dataset_name=\"train\", inference_dataset_name=\"test\", model_space=\"mnist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index and run ANN (commented out)\n",
    "# api.create_index()\n",
    "# results = api.get_nearest_neighbors(sample_from_embeddings[0], n_results=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results back from Chroma\n",
    "results = api.get_results(dataset_name=\"test\", n_results=15000)\n",
    "sample_from_crhoma_subset = [x for x in sample_from_dataset if x[2] in [y for y in results]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 15k results\n",
    "random_sample_from_dataset = torch.utils.data.Subset(sample_from_dataset, torch.randperm(len(sample_from_dataset))[:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/42457 (0%)]\tLoss: 2.297848\n",
      "Train Epoch: 1 [640/42457 (2%)]\tLoss: 1.385174\n",
      "Train Epoch: 1 [1280/42457 (3%)]\tLoss: 0.900825\n",
      "Train Epoch: 1 [1920/42457 (5%)]\tLoss: 0.691831\n",
      "Train Epoch: 1 [2560/42457 (6%)]\tLoss: 0.564817\n",
      "Train Epoch: 1 [3200/42457 (8%)]\tLoss: 0.382816\n",
      "Train Epoch: 1 [3840/42457 (9%)]\tLoss: 0.320076\n",
      "Train Epoch: 1 [4480/42457 (11%)]\tLoss: 0.321582\n",
      "Train Epoch: 1 [5120/42457 (12%)]\tLoss: 0.175594\n",
      "Train Epoch: 1 [5760/42457 (14%)]\tLoss: 0.264852\n",
      "Train Epoch: 1 [6400/42457 (15%)]\tLoss: 0.154354\n",
      "Train Epoch: 1 [7040/42457 (17%)]\tLoss: 0.175850\n",
      "Train Epoch: 1 [7680/42457 (18%)]\tLoss: 0.184211\n",
      "Train Epoch: 1 [8320/42457 (20%)]\tLoss: 0.221012\n",
      "Train Epoch: 1 [8960/42457 (21%)]\tLoss: 0.362074\n",
      "Train Epoch: 1 [9600/42457 (23%)]\tLoss: 0.463728\n",
      "Train Epoch: 1 [10240/42457 (24%)]\tLoss: 0.203111\n",
      "Train Epoch: 1 [10880/42457 (26%)]\tLoss: 0.127977\n",
      "Train Epoch: 1 [11520/42457 (27%)]\tLoss: 0.162777\n",
      "Train Epoch: 1 [12160/42457 (29%)]\tLoss: 0.152189\n",
      "Train Epoch: 1 [12800/42457 (30%)]\tLoss: 0.169918\n",
      "Train Epoch: 1 [13440/42457 (32%)]\tLoss: 0.103610\n",
      "Train Epoch: 1 [14080/42457 (33%)]\tLoss: 0.129688\n",
      "Train Epoch: 1 [14720/42457 (35%)]\tLoss: 0.074535\n",
      "Train Epoch: 1 [15360/42457 (36%)]\tLoss: 0.323674\n",
      "Train Epoch: 1 [16000/42457 (38%)]\tLoss: 0.137345\n",
      "Train Epoch: 1 [16640/42457 (39%)]\tLoss: 0.143172\n",
      "Train Epoch: 1 [17280/42457 (41%)]\tLoss: 0.041637\n",
      "Train Epoch: 1 [17920/42457 (42%)]\tLoss: 0.572905\n",
      "Train Epoch: 1 [18560/42457 (44%)]\tLoss: 0.129092\n",
      "Train Epoch: 1 [19200/42457 (45%)]\tLoss: 0.344369\n",
      "Train Epoch: 1 [19840/42457 (47%)]\tLoss: 0.058135\n",
      "Train Epoch: 1 [20480/42457 (48%)]\tLoss: 0.090238\n",
      "Train Epoch: 1 [21120/42457 (50%)]\tLoss: 0.179465\n",
      "Train Epoch: 1 [21760/42457 (51%)]\tLoss: 0.155980\n",
      "Train Epoch: 1 [22400/42457 (53%)]\tLoss: 0.231768\n",
      "Train Epoch: 1 [23040/42457 (54%)]\tLoss: 0.102351\n",
      "Train Epoch: 1 [23680/42457 (56%)]\tLoss: 0.145522\n",
      "Train Epoch: 1 [24320/42457 (57%)]\tLoss: 0.052690\n",
      "Train Epoch: 1 [24960/42457 (59%)]\tLoss: 0.136300\n",
      "Train Epoch: 1 [25600/42457 (60%)]\tLoss: 0.127744\n",
      "Train Epoch: 1 [26240/42457 (62%)]\tLoss: 0.056829\n",
      "Train Epoch: 1 [26880/42457 (63%)]\tLoss: 0.019790\n",
      "Train Epoch: 1 [27520/42457 (65%)]\tLoss: 0.243158\n",
      "Train Epoch: 1 [28160/42457 (66%)]\tLoss: 0.153574\n",
      "Train Epoch: 1 [28800/42457 (68%)]\tLoss: 0.124066\n",
      "Train Epoch: 1 [29440/42457 (69%)]\tLoss: 0.117737\n",
      "Train Epoch: 1 [30080/42457 (71%)]\tLoss: 0.186425\n",
      "Train Epoch: 1 [30720/42457 (72%)]\tLoss: 0.142118\n",
      "Train Epoch: 1 [31360/42457 (74%)]\tLoss: 0.199634\n",
      "Train Epoch: 1 [32000/42457 (75%)]\tLoss: 0.112563\n",
      "Train Epoch: 1 [32640/42457 (77%)]\tLoss: 0.061044\n",
      "Train Epoch: 1 [33280/42457 (78%)]\tLoss: 0.305184\n",
      "Train Epoch: 1 [33920/42457 (80%)]\tLoss: 0.057269\n",
      "Train Epoch: 1 [34560/42457 (81%)]\tLoss: 0.205046\n",
      "Train Epoch: 1 [35200/42457 (83%)]\tLoss: 0.210137\n",
      "Train Epoch: 1 [35840/42457 (84%)]\tLoss: 0.205234\n",
      "Train Epoch: 1 [36480/42457 (86%)]\tLoss: 0.172561\n",
      "Train Epoch: 1 [37120/42457 (87%)]\tLoss: 0.188868\n",
      "Train Epoch: 1 [37760/42457 (89%)]\tLoss: 0.276153\n",
      "Train Epoch: 1 [38400/42457 (90%)]\tLoss: 0.236738\n",
      "Train Epoch: 1 [39040/42457 (92%)]\tLoss: 0.273558\n",
      "Train Epoch: 1 [39680/42457 (93%)]\tLoss: 0.200243\n",
      "Train Epoch: 1 [40320/42457 (95%)]\tLoss: 0.320339\n",
      "Train Epoch: 1 [40960/42457 (96%)]\tLoss: 0.144285\n",
      "Train Epoch: 1 [41600/42457 (98%)]\tLoss: 0.447156\n",
      "Train Epoch: 1 [42240/42457 (99%)]\tLoss: 0.350211\n",
      "\n",
      "Test set: Average loss: 0.0481, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Train Epoch: 2 [0/42457 (0%)]\tLoss: 0.074306\n",
      "Train Epoch: 2 [640/42457 (2%)]\tLoss: 0.059764\n",
      "Train Epoch: 2 [1280/42457 (3%)]\tLoss: 0.048015\n",
      "Train Epoch: 2 [1920/42457 (5%)]\tLoss: 0.097972\n",
      "Train Epoch: 2 [2560/42457 (6%)]\tLoss: 0.026701\n",
      "Train Epoch: 2 [3200/42457 (8%)]\tLoss: 0.075997\n",
      "Train Epoch: 2 [3840/42457 (9%)]\tLoss: 0.068198\n",
      "Train Epoch: 2 [4480/42457 (11%)]\tLoss: 0.130904\n",
      "Train Epoch: 2 [5120/42457 (12%)]\tLoss: 0.076463\n",
      "Train Epoch: 2 [5760/42457 (14%)]\tLoss: 0.322102\n",
      "Train Epoch: 2 [6400/42457 (15%)]\tLoss: 0.007487\n",
      "Train Epoch: 2 [7040/42457 (17%)]\tLoss: 0.011032\n",
      "Train Epoch: 2 [7680/42457 (18%)]\tLoss: 0.026185\n",
      "Train Epoch: 2 [8320/42457 (20%)]\tLoss: 0.068975\n",
      "Train Epoch: 2 [8960/42457 (21%)]\tLoss: 0.260915\n",
      "Train Epoch: 2 [9600/42457 (23%)]\tLoss: 0.168923\n",
      "Train Epoch: 2 [10240/42457 (24%)]\tLoss: 0.077159\n",
      "Train Epoch: 2 [10880/42457 (26%)]\tLoss: 0.007212\n",
      "Train Epoch: 2 [11520/42457 (27%)]\tLoss: 0.038465\n",
      "Train Epoch: 2 [12160/42457 (29%)]\tLoss: 0.026062\n",
      "Train Epoch: 2 [12800/42457 (30%)]\tLoss: 0.155706\n",
      "Train Epoch: 2 [13440/42457 (32%)]\tLoss: 0.081762\n",
      "Train Epoch: 2 [14080/42457 (33%)]\tLoss: 0.025286\n",
      "Train Epoch: 2 [14720/42457 (35%)]\tLoss: 0.056869\n",
      "Train Epoch: 2 [15360/42457 (36%)]\tLoss: 0.200687\n",
      "Train Epoch: 2 [16000/42457 (38%)]\tLoss: 0.053879\n",
      "Train Epoch: 2 [16640/42457 (39%)]\tLoss: 0.091754\n",
      "Train Epoch: 2 [17280/42457 (41%)]\tLoss: 0.015431\n",
      "Train Epoch: 2 [17920/42457 (42%)]\tLoss: 0.220703\n",
      "Train Epoch: 2 [18560/42457 (44%)]\tLoss: 0.028678\n",
      "Train Epoch: 2 [19200/42457 (45%)]\tLoss: 0.051420\n",
      "Train Epoch: 2 [19840/42457 (47%)]\tLoss: 0.031527\n",
      "Train Epoch: 2 [20480/42457 (48%)]\tLoss: 0.024555\n",
      "Train Epoch: 2 [21120/42457 (50%)]\tLoss: 0.072532\n",
      "Train Epoch: 2 [21760/42457 (51%)]\tLoss: 0.094750\n",
      "Train Epoch: 2 [22400/42457 (53%)]\tLoss: 0.018988\n",
      "Train Epoch: 2 [23040/42457 (54%)]\tLoss: 0.084219\n",
      "Train Epoch: 2 [23680/42457 (56%)]\tLoss: 0.038362\n",
      "Train Epoch: 2 [24320/42457 (57%)]\tLoss: 0.017147\n",
      "Train Epoch: 2 [24960/42457 (59%)]\tLoss: 0.078076\n",
      "Train Epoch: 2 [25600/42457 (60%)]\tLoss: 0.018774\n",
      "Train Epoch: 2 [26240/42457 (62%)]\tLoss: 0.010055\n",
      "Train Epoch: 2 [26880/42457 (63%)]\tLoss: 0.020725\n",
      "Train Epoch: 2 [27520/42457 (65%)]\tLoss: 0.076870\n",
      "Train Epoch: 2 [28160/42457 (66%)]\tLoss: 0.128058\n",
      "Train Epoch: 2 [28800/42457 (68%)]\tLoss: 0.099045\n",
      "Train Epoch: 2 [29440/42457 (69%)]\tLoss: 0.105080\n",
      "Train Epoch: 2 [30080/42457 (71%)]\tLoss: 0.046794\n",
      "Train Epoch: 2 [30720/42457 (72%)]\tLoss: 0.170643\n",
      "Train Epoch: 2 [31360/42457 (74%)]\tLoss: 0.108189\n",
      "Train Epoch: 2 [32000/42457 (75%)]\tLoss: 0.146044\n",
      "Train Epoch: 2 [32640/42457 (77%)]\tLoss: 0.021840\n",
      "Train Epoch: 2 [33280/42457 (78%)]\tLoss: 0.172396\n",
      "Train Epoch: 2 [33920/42457 (80%)]\tLoss: 0.006158\n",
      "Train Epoch: 2 [34560/42457 (81%)]\tLoss: 0.187076\n",
      "Train Epoch: 2 [35200/42457 (83%)]\tLoss: 0.147185\n",
      "Train Epoch: 2 [35840/42457 (84%)]\tLoss: 0.175188\n",
      "Train Epoch: 2 [36480/42457 (86%)]\tLoss: 0.112955\n",
      "Train Epoch: 2 [37120/42457 (87%)]\tLoss: 0.053103\n",
      "Train Epoch: 2 [37760/42457 (89%)]\tLoss: 0.148658\n",
      "Train Epoch: 2 [38400/42457 (90%)]\tLoss: 0.077893\n",
      "Train Epoch: 2 [39040/42457 (92%)]\tLoss: 0.289602\n",
      "Train Epoch: 2 [39680/42457 (93%)]\tLoss: 0.163144\n",
      "Train Epoch: 2 [40320/42457 (95%)]\tLoss: 0.127425\n",
      "Train Epoch: 2 [40960/42457 (96%)]\tLoss: 0.078041\n",
      "Train Epoch: 2 [41600/42457 (98%)]\tLoss: 0.441317\n",
      "Train Epoch: 2 [42240/42457 (99%)]\tLoss: 0.323423\n",
      "\n",
      "Test set: Average loss: 0.0342, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/42457 (0%)]\tLoss: 0.065036\n",
      "Train Epoch: 3 [640/42457 (2%)]\tLoss: 0.007448\n",
      "Train Epoch: 3 [1280/42457 (3%)]\tLoss: 0.042392\n",
      "Train Epoch: 3 [1920/42457 (5%)]\tLoss: 0.079230\n",
      "Train Epoch: 3 [2560/42457 (6%)]\tLoss: 0.024592\n",
      "Train Epoch: 3 [3200/42457 (8%)]\tLoss: 0.062560\n",
      "Train Epoch: 3 [3840/42457 (9%)]\tLoss: 0.032035\n",
      "Train Epoch: 3 [4480/42457 (11%)]\tLoss: 0.107991\n",
      "Train Epoch: 3 [5120/42457 (12%)]\tLoss: 0.011465\n",
      "Train Epoch: 3 [5760/42457 (14%)]\tLoss: 0.177948\n",
      "Train Epoch: 3 [6400/42457 (15%)]\tLoss: 0.003171\n",
      "Train Epoch: 3 [7040/42457 (17%)]\tLoss: 0.010069\n",
      "Train Epoch: 3 [7680/42457 (18%)]\tLoss: 0.012899\n",
      "Train Epoch: 3 [8320/42457 (20%)]\tLoss: 0.061359\n",
      "Train Epoch: 3 [8960/42457 (21%)]\tLoss: 0.104634\n",
      "Train Epoch: 3 [9600/42457 (23%)]\tLoss: 0.013517\n",
      "Train Epoch: 3 [10240/42457 (24%)]\tLoss: 0.073365\n",
      "Train Epoch: 3 [10880/42457 (26%)]\tLoss: 0.008378\n",
      "Train Epoch: 3 [11520/42457 (27%)]\tLoss: 0.017266\n",
      "Train Epoch: 3 [12160/42457 (29%)]\tLoss: 0.012760\n",
      "Train Epoch: 3 [12800/42457 (30%)]\tLoss: 0.262617\n",
      "Train Epoch: 3 [13440/42457 (32%)]\tLoss: 0.007846\n",
      "Train Epoch: 3 [14080/42457 (33%)]\tLoss: 0.050349\n",
      "Train Epoch: 3 [14720/42457 (35%)]\tLoss: 0.016422\n",
      "Train Epoch: 3 [15360/42457 (36%)]\tLoss: 0.013313\n",
      "Train Epoch: 3 [16000/42457 (38%)]\tLoss: 0.010888\n",
      "Train Epoch: 3 [16640/42457 (39%)]\tLoss: 0.027698\n",
      "Train Epoch: 3 [17280/42457 (41%)]\tLoss: 0.032217\n",
      "Train Epoch: 3 [17920/42457 (42%)]\tLoss: 0.286798\n",
      "Train Epoch: 3 [18560/42457 (44%)]\tLoss: 0.039476\n",
      "Train Epoch: 3 [19200/42457 (45%)]\tLoss: 0.118574\n",
      "Train Epoch: 3 [19840/42457 (47%)]\tLoss: 0.064269\n",
      "Train Epoch: 3 [20480/42457 (48%)]\tLoss: 0.009556\n",
      "Train Epoch: 3 [21120/42457 (50%)]\tLoss: 0.107536\n",
      "Train Epoch: 3 [21760/42457 (51%)]\tLoss: 0.016715\n",
      "Train Epoch: 3 [22400/42457 (53%)]\tLoss: 0.030122\n",
      "Train Epoch: 3 [23040/42457 (54%)]\tLoss: 0.033627\n",
      "Train Epoch: 3 [23680/42457 (56%)]\tLoss: 0.041245\n",
      "Train Epoch: 3 [24320/42457 (57%)]\tLoss: 0.007505\n",
      "Train Epoch: 3 [24960/42457 (59%)]\tLoss: 0.014193\n",
      "Train Epoch: 3 [25600/42457 (60%)]\tLoss: 0.002240\n",
      "Train Epoch: 3 [26240/42457 (62%)]\tLoss: 0.003627\n",
      "Train Epoch: 3 [26880/42457 (63%)]\tLoss: 0.013194\n",
      "Train Epoch: 3 [27520/42457 (65%)]\tLoss: 0.014872\n",
      "Train Epoch: 3 [28160/42457 (66%)]\tLoss: 0.054112\n",
      "Train Epoch: 3 [28800/42457 (68%)]\tLoss: 0.029713\n",
      "Train Epoch: 3 [29440/42457 (69%)]\tLoss: 0.038781\n",
      "Train Epoch: 3 [30080/42457 (71%)]\tLoss: 0.059994\n",
      "Train Epoch: 3 [30720/42457 (72%)]\tLoss: 0.061289\n",
      "Train Epoch: 3 [31360/42457 (74%)]\tLoss: 0.035410\n",
      "Train Epoch: 3 [32000/42457 (75%)]\tLoss: 0.066327\n",
      "Train Epoch: 3 [32640/42457 (77%)]\tLoss: 0.028222\n",
      "Train Epoch: 3 [33280/42457 (78%)]\tLoss: 0.228382\n",
      "Train Epoch: 3 [33920/42457 (80%)]\tLoss: 0.002885\n",
      "Train Epoch: 3 [34560/42457 (81%)]\tLoss: 0.096590\n",
      "Train Epoch: 3 [35200/42457 (83%)]\tLoss: 0.140328\n",
      "Train Epoch: 3 [35840/42457 (84%)]\tLoss: 0.110933\n",
      "Train Epoch: 3 [36480/42457 (86%)]\tLoss: 0.083198\n",
      "Train Epoch: 3 [37120/42457 (87%)]\tLoss: 0.065192\n",
      "Train Epoch: 3 [37760/42457 (89%)]\tLoss: 0.054941\n",
      "Train Epoch: 3 [38400/42457 (90%)]\tLoss: 0.090108\n",
      "Train Epoch: 3 [39040/42457 (92%)]\tLoss: 0.223787\n",
      "Train Epoch: 3 [39680/42457 (93%)]\tLoss: 0.072785\n",
      "Train Epoch: 3 [40320/42457 (95%)]\tLoss: 0.034438\n",
      "Train Epoch: 3 [40960/42457 (96%)]\tLoss: 0.082621\n",
      "Train Epoch: 3 [41600/42457 (98%)]\tLoss: 0.316326\n",
      "Train Epoch: 3 [42240/42457 (99%)]\tLoss: 0.140909\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 9897/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/42457 (0%)]\tLoss: 0.101506\n",
      "Train Epoch: 4 [640/42457 (2%)]\tLoss: 0.018976\n",
      "Train Epoch: 4 [1280/42457 (3%)]\tLoss: 0.080718\n",
      "Train Epoch: 4 [1920/42457 (5%)]\tLoss: 0.118171\n",
      "Train Epoch: 4 [2560/42457 (6%)]\tLoss: 0.002922\n",
      "Train Epoch: 4 [3200/42457 (8%)]\tLoss: 0.054481\n",
      "Train Epoch: 4 [3840/42457 (9%)]\tLoss: 0.014713\n",
      "Train Epoch: 4 [4480/42457 (11%)]\tLoss: 0.113094\n",
      "Train Epoch: 4 [5120/42457 (12%)]\tLoss: 0.041509\n",
      "Train Epoch: 4 [5760/42457 (14%)]\tLoss: 0.240728\n",
      "Train Epoch: 4 [6400/42457 (15%)]\tLoss: 0.002380\n",
      "Train Epoch: 4 [7040/42457 (17%)]\tLoss: 0.028677\n",
      "Train Epoch: 4 [7680/42457 (18%)]\tLoss: 0.022543\n",
      "Train Epoch: 4 [8320/42457 (20%)]\tLoss: 0.006513\n",
      "Train Epoch: 4 [8960/42457 (21%)]\tLoss: 0.208374\n",
      "Train Epoch: 4 [9600/42457 (23%)]\tLoss: 0.021750\n",
      "Train Epoch: 4 [10240/42457 (24%)]\tLoss: 0.007246\n",
      "Train Epoch: 4 [10880/42457 (26%)]\tLoss: 0.003053\n",
      "Train Epoch: 4 [11520/42457 (27%)]\tLoss: 0.011473\n",
      "Train Epoch: 4 [12160/42457 (29%)]\tLoss: 0.003324\n",
      "Train Epoch: 4 [12800/42457 (30%)]\tLoss: 0.079316\n",
      "Train Epoch: 4 [13440/42457 (32%)]\tLoss: 0.014867\n",
      "Train Epoch: 4 [14080/42457 (33%)]\tLoss: 0.005580\n",
      "Train Epoch: 4 [14720/42457 (35%)]\tLoss: 0.009051\n",
      "Train Epoch: 4 [15360/42457 (36%)]\tLoss: 0.070706\n",
      "Train Epoch: 4 [16000/42457 (38%)]\tLoss: 0.002414\n",
      "Train Epoch: 4 [16640/42457 (39%)]\tLoss: 0.072485\n",
      "Train Epoch: 4 [17280/42457 (41%)]\tLoss: 0.002122\n",
      "Train Epoch: 4 [17920/42457 (42%)]\tLoss: 0.301933\n",
      "Train Epoch: 4 [18560/42457 (44%)]\tLoss: 0.038023\n",
      "Train Epoch: 4 [19200/42457 (45%)]\tLoss: 0.056749\n",
      "Train Epoch: 4 [19840/42457 (47%)]\tLoss: 0.003872\n",
      "Train Epoch: 4 [20480/42457 (48%)]\tLoss: 0.046432\n",
      "Train Epoch: 4 [21120/42457 (50%)]\tLoss: 0.066697\n",
      "Train Epoch: 4 [21760/42457 (51%)]\tLoss: 0.066332\n",
      "Train Epoch: 4 [22400/42457 (53%)]\tLoss: 0.011316\n",
      "Train Epoch: 4 [23040/42457 (54%)]\tLoss: 0.025653\n",
      "Train Epoch: 4 [23680/42457 (56%)]\tLoss: 0.009620\n",
      "Train Epoch: 4 [24320/42457 (57%)]\tLoss: 0.064836\n",
      "Train Epoch: 4 [24960/42457 (59%)]\tLoss: 0.003769\n",
      "Train Epoch: 4 [25600/42457 (60%)]\tLoss: 0.002997\n",
      "Train Epoch: 4 [26240/42457 (62%)]\tLoss: 0.014098\n",
      "Train Epoch: 4 [26880/42457 (63%)]\tLoss: 0.013574\n",
      "Train Epoch: 4 [27520/42457 (65%)]\tLoss: 0.026960\n",
      "Train Epoch: 4 [28160/42457 (66%)]\tLoss: 0.083957\n",
      "Train Epoch: 4 [28800/42457 (68%)]\tLoss: 0.015844\n",
      "Train Epoch: 4 [29440/42457 (69%)]\tLoss: 0.011482\n",
      "Train Epoch: 4 [30080/42457 (71%)]\tLoss: 0.032508\n",
      "Train Epoch: 4 [30720/42457 (72%)]\tLoss: 0.061946\n",
      "Train Epoch: 4 [31360/42457 (74%)]\tLoss: 0.024457\n",
      "Train Epoch: 4 [32000/42457 (75%)]\tLoss: 0.066970\n",
      "Train Epoch: 4 [32640/42457 (77%)]\tLoss: 0.005422\n",
      "Train Epoch: 4 [33280/42457 (78%)]\tLoss: 0.083629\n",
      "Train Epoch: 4 [33920/42457 (80%)]\tLoss: 0.002144\n",
      "Train Epoch: 4 [34560/42457 (81%)]\tLoss: 0.055706\n",
      "Train Epoch: 4 [35200/42457 (83%)]\tLoss: 0.073687\n",
      "Train Epoch: 4 [35840/42457 (84%)]\tLoss: 0.088606\n",
      "Train Epoch: 4 [36480/42457 (86%)]\tLoss: 0.084674\n",
      "Train Epoch: 4 [37120/42457 (87%)]\tLoss: 0.066320\n",
      "Train Epoch: 4 [37760/42457 (89%)]\tLoss: 0.056939\n",
      "Train Epoch: 4 [38400/42457 (90%)]\tLoss: 0.045934\n",
      "Train Epoch: 4 [39040/42457 (92%)]\tLoss: 0.105664\n",
      "Train Epoch: 4 [39680/42457 (93%)]\tLoss: 0.097934\n",
      "Train Epoch: 4 [40320/42457 (95%)]\tLoss: 0.030919\n",
      "Train Epoch: 4 [40960/42457 (96%)]\tLoss: 0.118534\n",
      "Train Epoch: 4 [41600/42457 (98%)]\tLoss: 0.225115\n",
      "Train Epoch: 4 [42240/42457 (99%)]\tLoss: 0.097823\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/42457 (0%)]\tLoss: 0.091008\n",
      "Train Epoch: 5 [640/42457 (2%)]\tLoss: 0.003218\n",
      "Train Epoch: 5 [1280/42457 (3%)]\tLoss: 0.043038\n",
      "Train Epoch: 5 [1920/42457 (5%)]\tLoss: 0.024965\n",
      "Train Epoch: 5 [2560/42457 (6%)]\tLoss: 0.010388\n",
      "Train Epoch: 5 [3200/42457 (8%)]\tLoss: 0.064527\n",
      "Train Epoch: 5 [3840/42457 (9%)]\tLoss: 0.008578\n",
      "Train Epoch: 5 [4480/42457 (11%)]\tLoss: 0.163920\n",
      "Train Epoch: 5 [5120/42457 (12%)]\tLoss: 0.040535\n",
      "Train Epoch: 5 [5760/42457 (14%)]\tLoss: 0.191606\n",
      "Train Epoch: 5 [6400/42457 (15%)]\tLoss: 0.007146\n",
      "Train Epoch: 5 [7040/42457 (17%)]\tLoss: 0.029004\n",
      "Train Epoch: 5 [7680/42457 (18%)]\tLoss: 0.010431\n",
      "Train Epoch: 5 [8320/42457 (20%)]\tLoss: 0.076867\n",
      "Train Epoch: 5 [8960/42457 (21%)]\tLoss: 0.086051\n",
      "Train Epoch: 5 [9600/42457 (23%)]\tLoss: 0.053342\n",
      "Train Epoch: 5 [10240/42457 (24%)]\tLoss: 0.006318\n",
      "Train Epoch: 5 [10880/42457 (26%)]\tLoss: 0.002927\n",
      "Train Epoch: 5 [11520/42457 (27%)]\tLoss: 0.015029\n",
      "Train Epoch: 5 [12160/42457 (29%)]\tLoss: 0.007880\n",
      "Train Epoch: 5 [12800/42457 (30%)]\tLoss: 0.089830\n",
      "Train Epoch: 5 [13440/42457 (32%)]\tLoss: 0.014876\n",
      "Train Epoch: 5 [14080/42457 (33%)]\tLoss: 0.040365\n",
      "Train Epoch: 5 [14720/42457 (35%)]\tLoss: 0.003056\n",
      "Train Epoch: 5 [15360/42457 (36%)]\tLoss: 0.006653\n",
      "Train Epoch: 5 [16000/42457 (38%)]\tLoss: 0.015113\n",
      "Train Epoch: 5 [16640/42457 (39%)]\tLoss: 0.018815\n",
      "Train Epoch: 5 [17280/42457 (41%)]\tLoss: 0.002200\n",
      "Train Epoch: 5 [17920/42457 (42%)]\tLoss: 0.165583\n",
      "Train Epoch: 5 [18560/42457 (44%)]\tLoss: 0.014389\n",
      "Train Epoch: 5 [19200/42457 (45%)]\tLoss: 0.005470\n",
      "Train Epoch: 5 [19840/42457 (47%)]\tLoss: 0.003225\n",
      "Train Epoch: 5 [20480/42457 (48%)]\tLoss: 0.044299\n",
      "Train Epoch: 5 [21120/42457 (50%)]\tLoss: 0.060710\n",
      "Train Epoch: 5 [21760/42457 (51%)]\tLoss: 0.014467\n",
      "Train Epoch: 5 [22400/42457 (53%)]\tLoss: 0.013787\n",
      "Train Epoch: 5 [23040/42457 (54%)]\tLoss: 0.023711\n",
      "Train Epoch: 5 [23680/42457 (56%)]\tLoss: 0.028934\n",
      "Train Epoch: 5 [24320/42457 (57%)]\tLoss: 0.007182\n",
      "Train Epoch: 5 [24960/42457 (59%)]\tLoss: 0.024255\n",
      "Train Epoch: 5 [25600/42457 (60%)]\tLoss: 0.001288\n",
      "Train Epoch: 5 [26240/42457 (62%)]\tLoss: 0.006326\n",
      "Train Epoch: 5 [26880/42457 (63%)]\tLoss: 0.003124\n",
      "Train Epoch: 5 [27520/42457 (65%)]\tLoss: 0.008736\n",
      "Train Epoch: 5 [28160/42457 (66%)]\tLoss: 0.031818\n",
      "Train Epoch: 5 [28800/42457 (68%)]\tLoss: 0.024020\n",
      "Train Epoch: 5 [29440/42457 (69%)]\tLoss: 0.019825\n",
      "Train Epoch: 5 [30080/42457 (71%)]\tLoss: 0.018512\n",
      "Train Epoch: 5 [30720/42457 (72%)]\tLoss: 0.005336\n",
      "Train Epoch: 5 [31360/42457 (74%)]\tLoss: 0.019651\n",
      "Train Epoch: 5 [32000/42457 (75%)]\tLoss: 0.014176\n",
      "Train Epoch: 5 [32640/42457 (77%)]\tLoss: 0.025742\n",
      "Train Epoch: 5 [33280/42457 (78%)]\tLoss: 0.181746\n",
      "Train Epoch: 5 [33920/42457 (80%)]\tLoss: 0.003138\n",
      "Train Epoch: 5 [34560/42457 (81%)]\tLoss: 0.018000\n",
      "Train Epoch: 5 [35200/42457 (83%)]\tLoss: 0.079950\n",
      "Train Epoch: 5 [35840/42457 (84%)]\tLoss: 0.065277\n",
      "Train Epoch: 5 [36480/42457 (86%)]\tLoss: 0.034025\n",
      "Train Epoch: 5 [37120/42457 (87%)]\tLoss: 0.037039\n",
      "Train Epoch: 5 [37760/42457 (89%)]\tLoss: 0.042077\n",
      "Train Epoch: 5 [38400/42457 (90%)]\tLoss: 0.026075\n",
      "Train Epoch: 5 [39040/42457 (92%)]\tLoss: 0.104991\n",
      "Train Epoch: 5 [39680/42457 (93%)]\tLoss: 0.062837\n",
      "Train Epoch: 5 [40320/42457 (95%)]\tLoss: 0.056444\n",
      "Train Epoch: 5 [40960/42457 (96%)]\tLoss: 0.064673\n",
      "Train Epoch: 5 [41600/42457 (98%)]\tLoss: 0.050442\n",
      "Train Epoch: 5 [42240/42457 (99%)]\tLoss: 0.068535\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 9908/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train from scratch on the original cut and the sampled results\n",
    "\n",
    "# Create a dataloader which is a combination of the original cut and the sampled results\n",
    "train_sampled_dataset = torch.utils.data.ConcatDataset([train_dataset, sample_from_crhoma_subset])\n",
    "train_sampled_loader = torch.utils.data.DataLoader(train_sampled_dataset, **train_kwargs)\n",
    "\n",
    "sampled_model = Net()\n",
    "optimizer = optim.Adadelta(sampled_model.parameters(), lr=1.0)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "# Train and test our model\n",
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    # Train\n",
    "    sampled_model.train()\n",
    "    # emumerate through the dataloader\n",
    "    for batch_idx, (data, target, _) in enumerate(train_sampled_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = sampled_model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10== 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_sampled_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_sampled_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Determine Loss on the test set\n",
    "    sampled_model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = sampled_model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(sampled_model.state_dict(), \"mnist_cnn_sampled.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/45000 (0%)]\tLoss: 2.307080\n",
      "Train Epoch: 1 [640/45000 (1%)]\tLoss: 1.711250\n",
      "Train Epoch: 1 [1280/45000 (3%)]\tLoss: 0.790761\n",
      "Train Epoch: 1 [1920/45000 (4%)]\tLoss: 0.837130\n",
      "Train Epoch: 1 [2560/45000 (6%)]\tLoss: 0.409986\n",
      "Train Epoch: 1 [3200/45000 (7%)]\tLoss: 0.376750\n",
      "Train Epoch: 1 [3840/45000 (9%)]\tLoss: 0.215362\n",
      "Train Epoch: 1 [4480/45000 (10%)]\tLoss: 0.454628\n",
      "Train Epoch: 1 [5120/45000 (11%)]\tLoss: 0.182414\n",
      "Train Epoch: 1 [5760/45000 (13%)]\tLoss: 0.224168\n",
      "Train Epoch: 1 [6400/45000 (14%)]\tLoss: 0.178480\n",
      "Train Epoch: 1 [7040/45000 (16%)]\tLoss: 0.217367\n",
      "Train Epoch: 1 [7680/45000 (17%)]\tLoss: 0.258223\n",
      "Train Epoch: 1 [8320/45000 (18%)]\tLoss: 0.229271\n",
      "Train Epoch: 1 [8960/45000 (20%)]\tLoss: 0.604636\n",
      "Train Epoch: 1 [9600/45000 (21%)]\tLoss: 0.315153\n",
      "Train Epoch: 1 [10240/45000 (23%)]\tLoss: 0.187763\n",
      "Train Epoch: 1 [10880/45000 (24%)]\tLoss: 0.211865\n",
      "Train Epoch: 1 [11520/45000 (26%)]\tLoss: 0.163631\n",
      "Train Epoch: 1 [12160/45000 (27%)]\tLoss: 0.106323\n",
      "Train Epoch: 1 [12800/45000 (28%)]\tLoss: 0.326737\n",
      "Train Epoch: 1 [13440/45000 (30%)]\tLoss: 0.218411\n",
      "Train Epoch: 1 [14080/45000 (31%)]\tLoss: 0.176637\n",
      "Train Epoch: 1 [14720/45000 (33%)]\tLoss: 0.183372\n",
      "Train Epoch: 1 [15360/45000 (34%)]\tLoss: 0.293889\n",
      "Train Epoch: 1 [16000/45000 (36%)]\tLoss: 0.104450\n",
      "Train Epoch: 1 [16640/45000 (37%)]\tLoss: 0.152254\n",
      "Train Epoch: 1 [17280/45000 (38%)]\tLoss: 0.053142\n",
      "Train Epoch: 1 [17920/45000 (40%)]\tLoss: 0.308976\n",
      "Train Epoch: 1 [18560/45000 (41%)]\tLoss: 0.081475\n",
      "Train Epoch: 1 [19200/45000 (43%)]\tLoss: 0.240799\n",
      "Train Epoch: 1 [19840/45000 (44%)]\tLoss: 0.137575\n",
      "Train Epoch: 1 [20480/45000 (45%)]\tLoss: 0.283253\n",
      "Train Epoch: 1 [21120/45000 (47%)]\tLoss: 0.177495\n",
      "Train Epoch: 1 [21760/45000 (48%)]\tLoss: 0.112674\n",
      "Train Epoch: 1 [22400/45000 (50%)]\tLoss: 0.088024\n",
      "Train Epoch: 1 [23040/45000 (51%)]\tLoss: 0.115697\n",
      "Train Epoch: 1 [23680/45000 (53%)]\tLoss: 0.105054\n",
      "Train Epoch: 1 [24320/45000 (54%)]\tLoss: 0.139346\n",
      "Train Epoch: 1 [24960/45000 (55%)]\tLoss: 0.199067\n",
      "Train Epoch: 1 [25600/45000 (57%)]\tLoss: 0.058115\n",
      "Train Epoch: 1 [26240/45000 (58%)]\tLoss: 0.053592\n",
      "Train Epoch: 1 [26880/45000 (60%)]\tLoss: 0.041628\n",
      "Train Epoch: 1 [27520/45000 (61%)]\tLoss: 0.120575\n",
      "Train Epoch: 1 [28160/45000 (62%)]\tLoss: 0.188125\n",
      "Train Epoch: 1 [28800/45000 (64%)]\tLoss: 0.149147\n",
      "Train Epoch: 1 [29440/45000 (65%)]\tLoss: 0.074382\n",
      "Train Epoch: 1 [30080/45000 (67%)]\tLoss: 0.121049\n",
      "Train Epoch: 1 [30720/45000 (68%)]\tLoss: 0.113281\n",
      "Train Epoch: 1 [31360/45000 (70%)]\tLoss: 0.150997\n",
      "Train Epoch: 1 [32000/45000 (71%)]\tLoss: 0.230023\n",
      "Train Epoch: 1 [32640/45000 (72%)]\tLoss: 0.374360\n",
      "Train Epoch: 1 [33280/45000 (74%)]\tLoss: 0.058916\n",
      "Train Epoch: 1 [33920/45000 (75%)]\tLoss: 0.119734\n",
      "Train Epoch: 1 [34560/45000 (77%)]\tLoss: 0.179492\n",
      "Train Epoch: 1 [35200/45000 (78%)]\tLoss: 0.169767\n",
      "Train Epoch: 1 [35840/45000 (80%)]\tLoss: 0.064510\n",
      "Train Epoch: 1 [36480/45000 (81%)]\tLoss: 0.091009\n",
      "Train Epoch: 1 [37120/45000 (82%)]\tLoss: 0.162690\n",
      "Train Epoch: 1 [37760/45000 (84%)]\tLoss: 0.031219\n",
      "Train Epoch: 1 [38400/45000 (85%)]\tLoss: 0.089921\n",
      "Train Epoch: 1 [39040/45000 (87%)]\tLoss: 0.110873\n",
      "Train Epoch: 1 [39680/45000 (88%)]\tLoss: 0.165658\n",
      "Train Epoch: 1 [40320/45000 (89%)]\tLoss: 0.048963\n",
      "Train Epoch: 1 [40960/45000 (91%)]\tLoss: 0.059883\n",
      "Train Epoch: 1 [41600/45000 (92%)]\tLoss: 0.030902\n",
      "Train Epoch: 1 [42240/45000 (94%)]\tLoss: 0.050571\n",
      "Train Epoch: 1 [42880/45000 (95%)]\tLoss: 0.090842\n",
      "Train Epoch: 1 [43520/45000 (97%)]\tLoss: 0.184270\n",
      "Train Epoch: 1 [44160/45000 (98%)]\tLoss: 0.063948\n",
      "Train Epoch: 1 [44800/45000 (99%)]\tLoss: 0.124724\n",
      "\n",
      "Test set: Average loss: 0.0474, Accuracy: 9844/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/45000 (0%)]\tLoss: 0.093533\n",
      "Train Epoch: 2 [640/45000 (1%)]\tLoss: 0.034627\n",
      "Train Epoch: 2 [1280/45000 (3%)]\tLoss: 0.112722\n",
      "Train Epoch: 2 [1920/45000 (4%)]\tLoss: 0.080032\n",
      "Train Epoch: 2 [2560/45000 (6%)]\tLoss: 0.072727\n",
      "Train Epoch: 2 [3200/45000 (7%)]\tLoss: 0.075389\n",
      "Train Epoch: 2 [3840/45000 (9%)]\tLoss: 0.042545\n",
      "Train Epoch: 2 [4480/45000 (10%)]\tLoss: 0.106903\n",
      "Train Epoch: 2 [5120/45000 (11%)]\tLoss: 0.153276\n",
      "Train Epoch: 2 [5760/45000 (13%)]\tLoss: 0.239540\n",
      "Train Epoch: 2 [6400/45000 (14%)]\tLoss: 0.037586\n",
      "Train Epoch: 2 [7040/45000 (16%)]\tLoss: 0.086277\n",
      "Train Epoch: 2 [7680/45000 (17%)]\tLoss: 0.119351\n",
      "Train Epoch: 2 [8320/45000 (18%)]\tLoss: 0.045860\n",
      "Train Epoch: 2 [8960/45000 (20%)]\tLoss: 0.298579\n",
      "Train Epoch: 2 [9600/45000 (21%)]\tLoss: 0.095016\n",
      "Train Epoch: 2 [10240/45000 (23%)]\tLoss: 0.042016\n",
      "Train Epoch: 2 [10880/45000 (24%)]\tLoss: 0.037544\n",
      "Train Epoch: 2 [11520/45000 (26%)]\tLoss: 0.089129\n",
      "Train Epoch: 2 [12160/45000 (27%)]\tLoss: 0.011393\n",
      "Train Epoch: 2 [12800/45000 (28%)]\tLoss: 0.171274\n",
      "Train Epoch: 2 [13440/45000 (30%)]\tLoss: 0.071538\n",
      "Train Epoch: 2 [14080/45000 (31%)]\tLoss: 0.048039\n",
      "Train Epoch: 2 [14720/45000 (33%)]\tLoss: 0.012220\n",
      "Train Epoch: 2 [15360/45000 (34%)]\tLoss: 0.143737\n",
      "Train Epoch: 2 [16000/45000 (36%)]\tLoss: 0.016765\n",
      "Train Epoch: 2 [16640/45000 (37%)]\tLoss: 0.091084\n",
      "Train Epoch: 2 [17280/45000 (38%)]\tLoss: 0.012326\n",
      "Train Epoch: 2 [17920/45000 (40%)]\tLoss: 0.291710\n",
      "Train Epoch: 2 [18560/45000 (41%)]\tLoss: 0.025326\n",
      "Train Epoch: 2 [19200/45000 (43%)]\tLoss: 0.089177\n",
      "Train Epoch: 2 [19840/45000 (44%)]\tLoss: 0.037563\n",
      "Train Epoch: 2 [20480/45000 (45%)]\tLoss: 0.068113\n",
      "Train Epoch: 2 [21120/45000 (47%)]\tLoss: 0.162390\n",
      "Train Epoch: 2 [21760/45000 (48%)]\tLoss: 0.093018\n",
      "Train Epoch: 2 [22400/45000 (50%)]\tLoss: 0.047408\n",
      "Train Epoch: 2 [23040/45000 (51%)]\tLoss: 0.027380\n",
      "Train Epoch: 2 [23680/45000 (53%)]\tLoss: 0.034270\n",
      "Train Epoch: 2 [24320/45000 (54%)]\tLoss: 0.085563\n",
      "Train Epoch: 2 [24960/45000 (55%)]\tLoss: 0.040725\n",
      "Train Epoch: 2 [25600/45000 (57%)]\tLoss: 0.009929\n",
      "Train Epoch: 2 [26240/45000 (58%)]\tLoss: 0.007584\n",
      "Train Epoch: 2 [26880/45000 (60%)]\tLoss: 0.044723\n",
      "Train Epoch: 2 [27520/45000 (61%)]\tLoss: 0.053920\n",
      "Train Epoch: 2 [28160/45000 (62%)]\tLoss: 0.178356\n",
      "Train Epoch: 2 [28800/45000 (64%)]\tLoss: 0.052689\n",
      "Train Epoch: 2 [29440/45000 (65%)]\tLoss: 0.049866\n",
      "Train Epoch: 2 [30080/45000 (67%)]\tLoss: 0.110314\n",
      "Train Epoch: 2 [30720/45000 (68%)]\tLoss: 0.068153\n",
      "Train Epoch: 2 [31360/45000 (70%)]\tLoss: 0.106830\n",
      "Train Epoch: 2 [32000/45000 (71%)]\tLoss: 0.158252\n",
      "Train Epoch: 2 [32640/45000 (72%)]\tLoss: 0.109523\n",
      "Train Epoch: 2 [33280/45000 (74%)]\tLoss: 0.038151\n",
      "Train Epoch: 2 [33920/45000 (75%)]\tLoss: 0.191200\n",
      "Train Epoch: 2 [34560/45000 (77%)]\tLoss: 0.100903\n",
      "Train Epoch: 2 [35200/45000 (78%)]\tLoss: 0.098619\n",
      "Train Epoch: 2 [35840/45000 (80%)]\tLoss: 0.016652\n",
      "Train Epoch: 2 [36480/45000 (81%)]\tLoss: 0.105018\n",
      "Train Epoch: 2 [37120/45000 (82%)]\tLoss: 0.069715\n",
      "Train Epoch: 2 [37760/45000 (84%)]\tLoss: 0.018239\n",
      "Train Epoch: 2 [38400/45000 (85%)]\tLoss: 0.140010\n",
      "Train Epoch: 2 [39040/45000 (87%)]\tLoss: 0.058532\n",
      "Train Epoch: 2 [39680/45000 (88%)]\tLoss: 0.114310\n",
      "Train Epoch: 2 [40320/45000 (89%)]\tLoss: 0.108970\n",
      "Train Epoch: 2 [40960/45000 (91%)]\tLoss: 0.010172\n",
      "Train Epoch: 2 [41600/45000 (92%)]\tLoss: 0.025562\n",
      "Train Epoch: 2 [42240/45000 (94%)]\tLoss: 0.064455\n",
      "Train Epoch: 2 [42880/45000 (95%)]\tLoss: 0.072257\n",
      "Train Epoch: 2 [43520/45000 (97%)]\tLoss: 0.056781\n",
      "Train Epoch: 2 [44160/45000 (98%)]\tLoss: 0.128679\n",
      "Train Epoch: 2 [44800/45000 (99%)]\tLoss: 0.117342\n",
      "\n",
      "Test set: Average loss: 0.0380, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/45000 (0%)]\tLoss: 0.159028\n",
      "Train Epoch: 3 [640/45000 (1%)]\tLoss: 0.022459\n",
      "Train Epoch: 3 [1280/45000 (3%)]\tLoss: 0.045278\n",
      "Train Epoch: 3 [1920/45000 (4%)]\tLoss: 0.060914\n",
      "Train Epoch: 3 [2560/45000 (6%)]\tLoss: 0.007796\n",
      "Train Epoch: 3 [3200/45000 (7%)]\tLoss: 0.072675\n",
      "Train Epoch: 3 [3840/45000 (9%)]\tLoss: 0.029522\n",
      "Train Epoch: 3 [4480/45000 (10%)]\tLoss: 0.038234\n",
      "Train Epoch: 3 [5120/45000 (11%)]\tLoss: 0.087163\n",
      "Train Epoch: 3 [5760/45000 (13%)]\tLoss: 0.270501\n",
      "Train Epoch: 3 [6400/45000 (14%)]\tLoss: 0.014299\n",
      "Train Epoch: 3 [7040/45000 (16%)]\tLoss: 0.033818\n",
      "Train Epoch: 3 [7680/45000 (17%)]\tLoss: 0.063662\n",
      "Train Epoch: 3 [8320/45000 (18%)]\tLoss: 0.020077\n",
      "Train Epoch: 3 [8960/45000 (20%)]\tLoss: 0.103877\n",
      "Train Epoch: 3 [9600/45000 (21%)]\tLoss: 0.151079\n",
      "Train Epoch: 3 [10240/45000 (23%)]\tLoss: 0.102441\n",
      "Train Epoch: 3 [10880/45000 (24%)]\tLoss: 0.030245\n",
      "Train Epoch: 3 [11520/45000 (26%)]\tLoss: 0.009029\n",
      "Train Epoch: 3 [12160/45000 (27%)]\tLoss: 0.003443\n",
      "Train Epoch: 3 [12800/45000 (28%)]\tLoss: 0.169252\n",
      "Train Epoch: 3 [13440/45000 (30%)]\tLoss: 0.031820\n",
      "Train Epoch: 3 [14080/45000 (31%)]\tLoss: 0.066274\n",
      "Train Epoch: 3 [14720/45000 (33%)]\tLoss: 0.037527\n",
      "Train Epoch: 3 [15360/45000 (34%)]\tLoss: 0.059634\n",
      "Train Epoch: 3 [16000/45000 (36%)]\tLoss: 0.006810\n",
      "Train Epoch: 3 [16640/45000 (37%)]\tLoss: 0.092537\n",
      "Train Epoch: 3 [17280/45000 (38%)]\tLoss: 0.007178\n",
      "Train Epoch: 3 [17920/45000 (40%)]\tLoss: 0.233231\n",
      "Train Epoch: 3 [18560/45000 (41%)]\tLoss: 0.033857\n",
      "Train Epoch: 3 [19200/45000 (43%)]\tLoss: 0.054738\n",
      "Train Epoch: 3 [19840/45000 (44%)]\tLoss: 0.023563\n",
      "Train Epoch: 3 [20480/45000 (45%)]\tLoss: 0.022992\n",
      "Train Epoch: 3 [21120/45000 (47%)]\tLoss: 0.053161\n",
      "Train Epoch: 3 [21760/45000 (48%)]\tLoss: 0.016217\n",
      "Train Epoch: 3 [22400/45000 (50%)]\tLoss: 0.045194\n",
      "Train Epoch: 3 [23040/45000 (51%)]\tLoss: 0.185068\n",
      "Train Epoch: 3 [23680/45000 (53%)]\tLoss: 0.044105\n",
      "Train Epoch: 3 [24320/45000 (54%)]\tLoss: 0.037996\n",
      "Train Epoch: 3 [24960/45000 (55%)]\tLoss: 0.023154\n",
      "Train Epoch: 3 [25600/45000 (57%)]\tLoss: 0.011347\n",
      "Train Epoch: 3 [26240/45000 (58%)]\tLoss: 0.020283\n",
      "Train Epoch: 3 [26880/45000 (60%)]\tLoss: 0.023558\n",
      "Train Epoch: 3 [27520/45000 (61%)]\tLoss: 0.054509\n",
      "Train Epoch: 3 [28160/45000 (62%)]\tLoss: 0.173141\n",
      "Train Epoch: 3 [28800/45000 (64%)]\tLoss: 0.049611\n",
      "Train Epoch: 3 [29440/45000 (65%)]\tLoss: 0.052324\n",
      "Train Epoch: 3 [30080/45000 (67%)]\tLoss: 0.016359\n",
      "Train Epoch: 3 [30720/45000 (68%)]\tLoss: 0.040452\n",
      "Train Epoch: 3 [31360/45000 (70%)]\tLoss: 0.035974\n",
      "Train Epoch: 3 [32000/45000 (71%)]\tLoss: 0.053548\n",
      "Train Epoch: 3 [32640/45000 (72%)]\tLoss: 0.025604\n",
      "Train Epoch: 3 [33280/45000 (74%)]\tLoss: 0.029645\n",
      "Train Epoch: 3 [33920/45000 (75%)]\tLoss: 0.004102\n",
      "Train Epoch: 3 [34560/45000 (77%)]\tLoss: 0.076725\n",
      "Train Epoch: 3 [35200/45000 (78%)]\tLoss: 0.092264\n",
      "Train Epoch: 3 [35840/45000 (80%)]\tLoss: 0.009681\n",
      "Train Epoch: 3 [36480/45000 (81%)]\tLoss: 0.039292\n",
      "Train Epoch: 3 [37120/45000 (82%)]\tLoss: 0.049074\n",
      "Train Epoch: 3 [37760/45000 (84%)]\tLoss: 0.008822\n",
      "Train Epoch: 3 [38400/45000 (85%)]\tLoss: 0.023850\n",
      "Train Epoch: 3 [39040/45000 (87%)]\tLoss: 0.042464\n",
      "Train Epoch: 3 [39680/45000 (88%)]\tLoss: 0.120579\n",
      "Train Epoch: 3 [40320/45000 (89%)]\tLoss: 0.089030\n",
      "Train Epoch: 3 [40960/45000 (91%)]\tLoss: 0.004857\n",
      "Train Epoch: 3 [41600/45000 (92%)]\tLoss: 0.012954\n",
      "Train Epoch: 3 [42240/45000 (94%)]\tLoss: 0.013705\n",
      "Train Epoch: 3 [42880/45000 (95%)]\tLoss: 0.023928\n",
      "Train Epoch: 3 [43520/45000 (97%)]\tLoss: 0.042745\n",
      "Train Epoch: 3 [44160/45000 (98%)]\tLoss: 0.045108\n",
      "Train Epoch: 3 [44800/45000 (99%)]\tLoss: 0.024168\n",
      "\n",
      "Test set: Average loss: 0.0372, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/45000 (0%)]\tLoss: 0.095028\n",
      "Train Epoch: 4 [640/45000 (1%)]\tLoss: 0.011371\n",
      "Train Epoch: 4 [1280/45000 (3%)]\tLoss: 0.044675\n",
      "Train Epoch: 4 [1920/45000 (4%)]\tLoss: 0.100785\n",
      "Train Epoch: 4 [2560/45000 (6%)]\tLoss: 0.005004\n",
      "Train Epoch: 4 [3200/45000 (7%)]\tLoss: 0.073829\n",
      "Train Epoch: 4 [3840/45000 (9%)]\tLoss: 0.009056\n",
      "Train Epoch: 4 [4480/45000 (10%)]\tLoss: 0.042115\n",
      "Train Epoch: 4 [5120/45000 (11%)]\tLoss: 0.056452\n",
      "Train Epoch: 4 [5760/45000 (13%)]\tLoss: 0.232389\n",
      "Train Epoch: 4 [6400/45000 (14%)]\tLoss: 0.013643\n",
      "Train Epoch: 4 [7040/45000 (16%)]\tLoss: 0.029045\n",
      "Train Epoch: 4 [7680/45000 (17%)]\tLoss: 0.017288\n",
      "Train Epoch: 4 [8320/45000 (18%)]\tLoss: 0.022808\n",
      "Train Epoch: 4 [8960/45000 (20%)]\tLoss: 0.038235\n",
      "Train Epoch: 4 [9600/45000 (21%)]\tLoss: 0.110219\n",
      "Train Epoch: 4 [10240/45000 (23%)]\tLoss: 0.073921\n",
      "Train Epoch: 4 [10880/45000 (24%)]\tLoss: 0.010109\n",
      "Train Epoch: 4 [11520/45000 (26%)]\tLoss: 0.002715\n",
      "Train Epoch: 4 [12160/45000 (27%)]\tLoss: 0.028691\n",
      "Train Epoch: 4 [12800/45000 (28%)]\tLoss: 0.138870\n",
      "Train Epoch: 4 [13440/45000 (30%)]\tLoss: 0.016497\n",
      "Train Epoch: 4 [14080/45000 (31%)]\tLoss: 0.017918\n",
      "Train Epoch: 4 [14720/45000 (33%)]\tLoss: 0.013946\n",
      "Train Epoch: 4 [15360/45000 (34%)]\tLoss: 0.085263\n",
      "Train Epoch: 4 [16000/45000 (36%)]\tLoss: 0.001643\n",
      "Train Epoch: 4 [16640/45000 (37%)]\tLoss: 0.006432\n",
      "Train Epoch: 4 [17280/45000 (38%)]\tLoss: 0.023963\n",
      "Train Epoch: 4 [17920/45000 (40%)]\tLoss: 0.285394\n",
      "Train Epoch: 4 [18560/45000 (41%)]\tLoss: 0.004251\n",
      "Train Epoch: 4 [19200/45000 (43%)]\tLoss: 0.044918\n",
      "Train Epoch: 4 [19840/45000 (44%)]\tLoss: 0.017200\n",
      "Train Epoch: 4 [20480/45000 (45%)]\tLoss: 0.008307\n",
      "Train Epoch: 4 [21120/45000 (47%)]\tLoss: 0.038940\n",
      "Train Epoch: 4 [21760/45000 (48%)]\tLoss: 0.050117\n",
      "Train Epoch: 4 [22400/45000 (50%)]\tLoss: 0.012453\n",
      "Train Epoch: 4 [23040/45000 (51%)]\tLoss: 0.069947\n",
      "Train Epoch: 4 [23680/45000 (53%)]\tLoss: 0.008581\n",
      "Train Epoch: 4 [24320/45000 (54%)]\tLoss: 0.015116\n",
      "Train Epoch: 4 [24960/45000 (55%)]\tLoss: 0.040353\n",
      "Train Epoch: 4 [25600/45000 (57%)]\tLoss: 0.004509\n",
      "Train Epoch: 4 [26240/45000 (58%)]\tLoss: 0.002979\n",
      "Train Epoch: 4 [26880/45000 (60%)]\tLoss: 0.004759\n",
      "Train Epoch: 4 [27520/45000 (61%)]\tLoss: 0.028477\n",
      "Train Epoch: 4 [28160/45000 (62%)]\tLoss: 0.091272\n",
      "Train Epoch: 4 [28800/45000 (64%)]\tLoss: 0.034807\n",
      "Train Epoch: 4 [29440/45000 (65%)]\tLoss: 0.019701\n",
      "Train Epoch: 4 [30080/45000 (67%)]\tLoss: 0.015151\n",
      "Train Epoch: 4 [30720/45000 (68%)]\tLoss: 0.043388\n",
      "Train Epoch: 4 [31360/45000 (70%)]\tLoss: 0.016388\n",
      "Train Epoch: 4 [32000/45000 (71%)]\tLoss: 0.103876\n",
      "Train Epoch: 4 [32640/45000 (72%)]\tLoss: 0.044843\n",
      "Train Epoch: 4 [33280/45000 (74%)]\tLoss: 0.052180\n",
      "Train Epoch: 4 [33920/45000 (75%)]\tLoss: 0.009655\n",
      "Train Epoch: 4 [34560/45000 (77%)]\tLoss: 0.046861\n",
      "Train Epoch: 4 [35200/45000 (78%)]\tLoss: 0.043642\n",
      "Train Epoch: 4 [35840/45000 (80%)]\tLoss: 0.007811\n",
      "Train Epoch: 4 [36480/45000 (81%)]\tLoss: 0.041325\n",
      "Train Epoch: 4 [37120/45000 (82%)]\tLoss: 0.041017\n",
      "Train Epoch: 4 [37760/45000 (84%)]\tLoss: 0.006055\n",
      "Train Epoch: 4 [38400/45000 (85%)]\tLoss: 0.006654\n",
      "Train Epoch: 4 [39040/45000 (87%)]\tLoss: 0.103911\n",
      "Train Epoch: 4 [39680/45000 (88%)]\tLoss: 0.045520\n",
      "Train Epoch: 4 [40320/45000 (89%)]\tLoss: 0.012045\n",
      "Train Epoch: 4 [40960/45000 (91%)]\tLoss: 0.018689\n",
      "Train Epoch: 4 [41600/45000 (92%)]\tLoss: 0.007026\n",
      "Train Epoch: 4 [42240/45000 (94%)]\tLoss: 0.007538\n",
      "Train Epoch: 4 [42880/45000 (95%)]\tLoss: 0.032268\n",
      "Train Epoch: 4 [43520/45000 (97%)]\tLoss: 0.029936\n",
      "Train Epoch: 4 [44160/45000 (98%)]\tLoss: 0.037381\n",
      "Train Epoch: 4 [44800/45000 (99%)]\tLoss: 0.020638\n",
      "\n",
      "Test set: Average loss: 0.0334, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/45000 (0%)]\tLoss: 0.023657\n",
      "Train Epoch: 5 [640/45000 (1%)]\tLoss: 0.011843\n",
      "Train Epoch: 5 [1280/45000 (3%)]\tLoss: 0.077065\n",
      "Train Epoch: 5 [1920/45000 (4%)]\tLoss: 0.085586\n",
      "Train Epoch: 5 [2560/45000 (6%)]\tLoss: 0.020585\n",
      "Train Epoch: 5 [3200/45000 (7%)]\tLoss: 0.035018\n",
      "Train Epoch: 5 [3840/45000 (9%)]\tLoss: 0.029960\n",
      "Train Epoch: 5 [4480/45000 (10%)]\tLoss: 0.068256\n",
      "Train Epoch: 5 [5120/45000 (11%)]\tLoss: 0.060751\n",
      "Train Epoch: 5 [5760/45000 (13%)]\tLoss: 0.118881\n",
      "Train Epoch: 5 [6400/45000 (14%)]\tLoss: 0.013052\n",
      "Train Epoch: 5 [7040/45000 (16%)]\tLoss: 0.010124\n",
      "Train Epoch: 5 [7680/45000 (17%)]\tLoss: 0.003002\n",
      "Train Epoch: 5 [8320/45000 (18%)]\tLoss: 0.026300\n",
      "Train Epoch: 5 [8960/45000 (20%)]\tLoss: 0.050002\n",
      "Train Epoch: 5 [9600/45000 (21%)]\tLoss: 0.042279\n",
      "Train Epoch: 5 [10240/45000 (23%)]\tLoss: 0.024582\n",
      "Train Epoch: 5 [10880/45000 (24%)]\tLoss: 0.005855\n",
      "Train Epoch: 5 [11520/45000 (26%)]\tLoss: 0.015429\n",
      "Train Epoch: 5 [12160/45000 (27%)]\tLoss: 0.001863\n",
      "Train Epoch: 5 [12800/45000 (28%)]\tLoss: 0.089783\n",
      "Train Epoch: 5 [13440/45000 (30%)]\tLoss: 0.019296\n",
      "Train Epoch: 5 [14080/45000 (31%)]\tLoss: 0.016151\n",
      "Train Epoch: 5 [14720/45000 (33%)]\tLoss: 0.005414\n",
      "Train Epoch: 5 [15360/45000 (34%)]\tLoss: 0.003268\n",
      "Train Epoch: 5 [16000/45000 (36%)]\tLoss: 0.027159\n",
      "Train Epoch: 5 [16640/45000 (37%)]\tLoss: 0.017448\n",
      "Train Epoch: 5 [17280/45000 (38%)]\tLoss: 0.005362\n",
      "Train Epoch: 5 [17920/45000 (40%)]\tLoss: 0.210934\n",
      "Train Epoch: 5 [18560/45000 (41%)]\tLoss: 0.005044\n",
      "Train Epoch: 5 [19200/45000 (43%)]\tLoss: 0.069955\n",
      "Train Epoch: 5 [19840/45000 (44%)]\tLoss: 0.006034\n",
      "Train Epoch: 5 [20480/45000 (45%)]\tLoss: 0.022888\n",
      "Train Epoch: 5 [21120/45000 (47%)]\tLoss: 0.055970\n",
      "Train Epoch: 5 [21760/45000 (48%)]\tLoss: 0.103911\n",
      "Train Epoch: 5 [22400/45000 (50%)]\tLoss: 0.035922\n",
      "Train Epoch: 5 [23040/45000 (51%)]\tLoss: 0.057368\n",
      "Train Epoch: 5 [23680/45000 (53%)]\tLoss: 0.024692\n",
      "Train Epoch: 5 [24320/45000 (54%)]\tLoss: 0.007918\n",
      "Train Epoch: 5 [24960/45000 (55%)]\tLoss: 0.011791\n",
      "Train Epoch: 5 [25600/45000 (57%)]\tLoss: 0.000769\n",
      "Train Epoch: 5 [26240/45000 (58%)]\tLoss: 0.003552\n",
      "Train Epoch: 5 [26880/45000 (60%)]\tLoss: 0.001642\n",
      "Train Epoch: 5 [27520/45000 (61%)]\tLoss: 0.032389\n",
      "Train Epoch: 5 [28160/45000 (62%)]\tLoss: 0.078508\n",
      "Train Epoch: 5 [28800/45000 (64%)]\tLoss: 0.010536\n",
      "Train Epoch: 5 [29440/45000 (65%)]\tLoss: 0.013124\n",
      "Train Epoch: 5 [30080/45000 (67%)]\tLoss: 0.014687\n",
      "Train Epoch: 5 [30720/45000 (68%)]\tLoss: 0.064846\n",
      "Train Epoch: 5 [31360/45000 (70%)]\tLoss: 0.014178\n",
      "Train Epoch: 5 [32000/45000 (71%)]\tLoss: 0.033180\n",
      "Train Epoch: 5 [32640/45000 (72%)]\tLoss: 0.021480\n",
      "Train Epoch: 5 [33280/45000 (74%)]\tLoss: 0.010449\n",
      "Train Epoch: 5 [33920/45000 (75%)]\tLoss: 0.037742\n",
      "Train Epoch: 5 [34560/45000 (77%)]\tLoss: 0.040664\n",
      "Train Epoch: 5 [35200/45000 (78%)]\tLoss: 0.025295\n",
      "Train Epoch: 5 [35840/45000 (80%)]\tLoss: 0.007531\n",
      "Train Epoch: 5 [36480/45000 (81%)]\tLoss: 0.046729\n",
      "Train Epoch: 5 [37120/45000 (82%)]\tLoss: 0.009853\n",
      "Train Epoch: 5 [37760/45000 (84%)]\tLoss: 0.003116\n",
      "Train Epoch: 5 [38400/45000 (85%)]\tLoss: 0.023790\n",
      "Train Epoch: 5 [39040/45000 (87%)]\tLoss: 0.009425\n",
      "Train Epoch: 5 [39680/45000 (88%)]\tLoss: 0.033856\n",
      "Train Epoch: 5 [40320/45000 (89%)]\tLoss: 0.005934\n",
      "Train Epoch: 5 [40960/45000 (91%)]\tLoss: 0.001800\n",
      "Train Epoch: 5 [41600/45000 (92%)]\tLoss: 0.003976\n",
      "Train Epoch: 5 [42240/45000 (94%)]\tLoss: 0.068319\n",
      "Train Epoch: 5 [42880/45000 (95%)]\tLoss: 0.068909\n",
      "Train Epoch: 5 [43520/45000 (97%)]\tLoss: 0.022379\n",
      "Train Epoch: 5 [44160/45000 (98%)]\tLoss: 0.033395\n",
      "Train Epoch: 5 [44800/45000 (99%)]\tLoss: 0.005756\n",
      "\n",
      "Test set: Average loss: 0.0315, Accuracy: 9899/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train from scratch on the original cut and the sampled results\n",
    "\n",
    "# Create a dataloader which is a combination of the original cut and the sampled results\n",
    "train_random_dataset = torch.utils.data.ConcatDataset([train_dataset, random_sample_from_dataset])\n",
    "train_random_loader = torch.utils.data.DataLoader(train_random_dataset, **train_kwargs)\n",
    "\n",
    "random_model = Net()\n",
    "optimizer = optim.Adadelta(random_model.parameters(), lr=1.0)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "# Train and test our model\n",
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    # Train\n",
    "    random_model.train()\n",
    "    # emumerate through the dataloader\n",
    "    for batch_idx, (data, target, _) in enumerate(train_random_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = random_model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10== 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_random_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_random_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Determine Loss on the test set\n",
    "    random_model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = random_model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(random_model.state_dict(), \"mnist_cnn_random.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cee379e823f0be65cc8e76dec88cd29dba28d635fb42abca317c93103c7b3ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
